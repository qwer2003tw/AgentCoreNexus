"""
Telegram Message Formatter - Format AI responses for Telegram
"""

import re
from typing import Any


class TelegramFormatter:
    """Telegram è¨Šæ¯æ ¼å¼åŒ–å™¨"""

    # Telegram è¨Šæ¯é•·åº¦é™åˆ¶
    MAX_MESSAGE_LENGTH = 4096

    def __init__(self, parse_mode: str | None = None):
        """
        åˆå§‹åŒ–æ ¼å¼åŒ–å™¨

        Args:
            parse_mode: è§£ææ¨¡å¼ ('Markdown', 'HTML', æˆ– None è¡¨ç¤ºç´”æ–‡å­—)
        """
        self.parse_mode = parse_mode

    def format(self, content: str, metadata: dict[str, Any] | None = None) -> str:
        """
        æ ¼å¼åŒ–è¨Šæ¯å…§å®¹

        Args:
            content: åŸå§‹è¨Šæ¯å…§å®¹
            metadata: é¡å¤–çš„å…ƒè³‡æ–™

        Returns:
            str: æ ¼å¼åŒ–å¾Œçš„è¨Šæ¯
        """
        # å¦‚æœè¨Šæ¯ç‚ºç©ºï¼Œè¿”å›é è¨­è¨Šæ¯
        if not content or not content.strip():
            return "âœ… è™•ç†å®Œæˆï¼ˆç„¡å›æ‡‰å…§å®¹ï¼‰"

        # ç§»é™¤éå¤šçš„ç©ºç™½è¡Œ
        formatted = self._normalize_whitespace(content)

        # å¦‚æœæœ‰å…ƒè³‡æ–™ï¼Œæ·»åŠ åˆ°è¨Šæ¯æœ«å°¾
        if metadata and self._should_include_metadata(metadata):
            formatted = self._append_metadata(formatted, metadata)

        # ç¢ºä¿è¨Šæ¯é•·åº¦ä¸è¶…éé™åˆ¶
        if len(formatted) > self.MAX_MESSAGE_LENGTH:
            formatted = self._truncate_message(formatted)

        return formatted

    def format_error(self, error_message: str, show_details: bool = False) -> str:
        """
        æ ¼å¼åŒ–éŒ¯èª¤è¨Šæ¯

        Args:
            error_message: éŒ¯èª¤è¨Šæ¯
            show_details: æ˜¯å¦é¡¯ç¤ºè©³ç´°éŒ¯èª¤

        Returns:
            str: æ ¼å¼åŒ–å¾Œçš„éŒ¯èª¤è¨Šæ¯
        """
        if show_details:
            return f"âŒ **è™•ç†å¤±æ•—**\n\néŒ¯èª¤è©³æƒ…ï¼š\n```\n{error_message}\n```"
        else:
            return "âŒ **è™•ç†å¤±æ•—**\n\næŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"

    def format_success(self, message: str = "") -> str:
        """
        æ ¼å¼åŒ–æˆåŠŸè¨Šæ¯

        Args:
            message: é¡å¤–çš„æˆåŠŸè¨Šæ¯

        Returns:
            str: æ ¼å¼åŒ–å¾Œçš„æˆåŠŸè¨Šæ¯
        """
        if message:
            return f"âœ… {message}"
        return "âœ… è™•ç†å®Œæˆ"

    def _normalize_whitespace(self, text: str) -> str:
        """
        æ­£è¦åŒ–ç©ºç™½å­—å…ƒï¼ˆç§»é™¤éå¤šçš„ç©ºç™½è¡Œï¼‰

        Args:
            text: åŸå§‹æ–‡å­—

        Returns:
            str: æ­£è¦åŒ–å¾Œçš„æ–‡å­—
        """
        # ç§»é™¤è¡Œå°¾ç©ºç™½
        text = re.sub(r"[ \t]+$", "", text, flags=re.MULTILINE)

        # å°‡é€£çºŒçš„ç©ºç™½è¡Œï¼ˆ3 è¡Œä»¥ä¸Šï¼‰å£“ç¸®ç‚º 2 è¡Œ
        text = re.sub(r"\n{3,}", "\n\n", text)

        # ç§»é™¤é–‹é ­å’Œçµå°¾çš„ç©ºç™½
        text = text.strip()

        return text

    def _should_include_metadata(self, metadata: dict[str, Any]) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²åŒ…å«å…ƒè³‡æ–™

        Args:
            metadata: å…ƒè³‡æ–™å­—å…¸

        Returns:
            bool: æ˜¯å¦åŒ…å«
        """
        # åªæœ‰åœ¨æœ‰æœ‰ç”¨è³‡è¨Šæ™‚æ‰åŒ…å«
        useful_keys = ["processing_time", "model", "tokens_used"]
        return any(key in metadata for key in useful_keys)

    def _append_metadata(self, content: str, metadata: dict[str, Any]) -> str:
        """
        æ·»åŠ å…ƒè³‡æ–™åˆ°è¨Šæ¯æœ«å°¾

        Args:
            content: åŸå§‹å…§å®¹
            metadata: å…ƒè³‡æ–™

        Returns:
            str: æ·»åŠ å…ƒè³‡æ–™å¾Œçš„å…§å®¹
        """
        meta_parts = []

        if "processing_time" in metadata:
            time_ms = metadata["processing_time"]
            if isinstance(time_ms, (int, float)):
                meta_parts.append(f"â± {time_ms:.0f}ms")

        if "model" in metadata:
            model = metadata["model"]
            if isinstance(model, str) and model:
                # ç°¡åŒ–æ¨¡å‹åç¨±ï¼ˆä¾‹å¦‚ "claude-3-sonnet" â†’ "Sonnet"ï¼‰
                simplified_model = self._simplify_model_name(model)
                meta_parts.append(f"ğŸ¤– {simplified_model}")

        if "tokens_used" in metadata:
            tokens = metadata["tokens_used"]
            if isinstance(tokens, int):
                meta_parts.append(f"ğŸ“Š {tokens} tokens")

        if meta_parts:
            meta_text = " â€¢ ".join(meta_parts)
            return f"{content}\n\n---\n_{meta_text}_"

        return content

    def _simplify_model_name(self, model: str) -> str:
        """
        ç°¡åŒ–æ¨¡å‹åç¨±

        Args:
            model: å®Œæ•´æ¨¡å‹åç¨±

        Returns:
            str: ç°¡åŒ–å¾Œçš„åç¨±
        """
        # å¸¸è¦‹æ¨¡å‹ç°¡åŒ–
        simplifications = {
            "claude-3-opus": "Opus",
            "claude-3-sonnet": "Sonnet",
            "claude-3-haiku": "Haiku",
            "gpt-4": "GPT-4",
            "gpt-3.5-turbo": "GPT-3.5",
        }

        # æª¢æŸ¥ç²¾ç¢ºåŒ¹é…
        for full_name, simple_name in simplifications.items():
            if full_name in model.lower():
                return simple_name

        # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œè¿”å›åŸåç¨±ï¼ˆæˆªæ–·éé•·çš„åç¨±ï¼‰
        if len(model) > 20:
            return model[:17] + "..."
        return model

    def _truncate_message(self, text: str) -> str:
        """
        æˆªæ–·éé•·çš„è¨Šæ¯

        Args:
            text: åŸå§‹æ–‡å­—

        Returns:
            str: æˆªæ–·å¾Œçš„æ–‡å­—
        """
        # ä¿ç•™ä¸€äº›ç©ºé–“çµ¦æˆªæ–·æç¤º
        max_content_length = self.MAX_MESSAGE_LENGTH - 100

        if len(text) <= max_content_length:
            return text

        # æˆªæ–·ä¸¦æ·»åŠ æç¤º
        truncated = text[:max_content_length]

        # å˜—è©¦åœ¨æ®µè½é‚Šç•Œæˆªæ–·
        last_paragraph = truncated.rfind("\n\n")
        if last_paragraph > max_content_length * 0.8:
            truncated = truncated[:last_paragraph]

        # æ·»åŠ æˆªæ–·æç¤º
        truncated += f"\n\n---\nâš ï¸ _è¨Šæ¯éé•·ï¼Œå·²æˆªæ–·ï¼ˆå…± {len(text)} å­—å…ƒï¼‰_"

        return truncated

    def get_parse_mode(self) -> str | None:
        """
        å–å¾—ç•¶å‰çš„è§£ææ¨¡å¼

        Returns:
            Optional[str]: è§£ææ¨¡å¼
        """
        return self.parse_mode
