"""
æ¸¬è©¦éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶
"""

from botocore.exceptions import ClientError, EventStreamError

from utils.context_analyzer import analyze_context_size, estimate_tokens, should_truncate_context
from utils.error_messages import (
    format_error_response,
    get_user_friendly_error,
    should_suggest_new_conversation,
)
from utils.retry_handler import RetryHandler


class TestErrorMessages:
    """æ¸¬è©¦ç”¨æˆ¶å‹å–„éŒ¯èª¤è¨Šæ¯"""

    def test_bedrock_stream_error(self):
        """æ¸¬è©¦ Bedrock streaming éŒ¯èª¤è¨Šæ¯"""
        error = Exception("modelStreamErrorException in ConverseStream")
        msg = get_user_friendly_error(error)
        assert "AI æœå‹™" in msg
        assert "ç¨å¾Œå†è©¦" in msg

    def test_throttling_error(self):
        """æ¸¬è©¦é™æµéŒ¯èª¤è¨Šæ¯"""
        error = Exception("ThrottlingException: Rate limit exceeded")
        msg = get_user_friendly_error(error)
        assert "ç¹å¿™" in msg or "throttl" in msg.lower()

    def test_context_too_large(self):
        """æ¸¬è©¦ context éå¤§éŒ¯èª¤"""
        error = Exception("Context size limit exceeded")
        msg = get_user_friendly_error(error)
        assert "å°è©±æ­·å²" in msg or "context" in msg.lower()

    def test_memory_error(self):
        """æ¸¬è©¦ Memory éŒ¯èª¤è¨Šæ¯"""
        error = Exception("memory service error")
        msg = get_user_friendly_error(error, {"memory_error": True})
        assert "è¨˜æ†¶æœå‹™" in msg

    def test_timeout_error(self):
        """æ¸¬è©¦ Timeout éŒ¯èª¤è¨Šæ¯"""
        error = Exception("request timed out")
        msg = get_user_friendly_error(error)
        assert "æ™‚é–“éé•·" in msg or "timeout" in msg.lower()

    def test_file_processing_error(self):
        """æ¸¬è©¦æª”æ¡ˆè™•ç†éŒ¯èª¤"""
        error = Exception("file error")
        msg = get_user_friendly_error(error, {"processing_file": True})
        assert "æª”æ¡ˆè™•ç†" in msg

    def test_image_processing_error(self):
        """æ¸¬è©¦åœ–ç‰‡è™•ç†éŒ¯èª¤"""
        error = Exception("image error")
        msg = get_user_friendly_error(error, {"processing_image": True})
        assert "åœ–ç‰‡è™•ç†" in msg

    def test_generic_error(self):
        """æ¸¬è©¦é€šç”¨éŒ¯èª¤"""
        error = Exception("unknown error")
        msg = get_user_friendly_error(error)
        assert "ç³»çµ±è™•ç†" in msg or "å•é¡Œ" in msg

    def test_should_suggest_new_conversation(self):
        """æ¸¬è©¦æ˜¯å¦å»ºè­°æ–°å°è©±"""
        # Context ç›¸é—œéŒ¯èª¤æ‡‰è©²å»ºè­°æ–°å°è©±
        assert should_suggest_new_conversation("context limit exceeded") is True
        assert should_suggest_new_conversation("token limit reached") is True
        assert should_suggest_new_conversation("memory overflow") is True

        # å…¶ä»–éŒ¯èª¤ä¸å»ºè­°
        assert should_suggest_new_conversation("network error") is False

    def test_format_error_response_with_retry(self):
        """æ¸¬è©¦åŒ…å«é‡è©¦æ¬¡æ•¸çš„éŒ¯èª¤è¨Šæ¯"""
        error = Exception("EventStreamError")
        msg = format_error_response(error, {"retry_count": 2})
        assert "AI æœå‹™" in msg
        assert "é‡è©¦" in msg

    def test_format_error_response_without_hint(self):
        """æ¸¬è©¦ä¸åŒ…å«æç¤ºçš„éŒ¯èª¤è¨Šæ¯"""
        error = Exception("EventStreamError")
        msg = format_error_response(error, include_hint=False)
        assert "ğŸ’¡" not in msg  # ä¸æ‡‰è©²æœ‰æç¤ºç¬¦è™Ÿ


class TestRetryHandler:
    """æ¸¬è©¦é‡è©¦è™•ç†å™¨"""

    def test_retry_success_on_first_attempt(self):
        """æ¸¬è©¦ç¬¬ä¸€æ¬¡å˜—è©¦å°±æˆåŠŸ"""
        handler = RetryHandler(max_attempts=3)

        def success_func():
            return "success"

        result = handler.execute_with_retry(success_func)
        assert result["success"] is True
        assert result["attempts"] == 1

    def test_retry_success_after_failures(self):
        """æ¸¬è©¦å¤±æ•—å¾Œé‡è©¦æˆåŠŸ"""
        handler = RetryHandler(max_attempts=3, base_delay=0.1)
        call_count = [0]

        def flaky_func():
            call_count[0] += 1
            if call_count[0] < 3:
                raise EventStreamError({"Error": {"Message": "test"}}, "TestOp")
            return "success"

        result = handler.execute_with_retry(flaky_func)
        assert result["success"] is True
        assert result["attempts"] == 3

    def test_fallback_on_all_failures(self):
        """æ¸¬è©¦æ‰€æœ‰é‡è©¦å¤±æ•—å¾Œä½¿ç”¨é™ç´š"""
        handler = RetryHandler(max_attempts=2, base_delay=0.1)

        def always_fail():
            raise EventStreamError({"Error": {"Message": "error"}}, "TestOp")

        def fallback_func():
            return "fallback_result"

        result = handler.execute_with_retry(always_fail, fallback_func=fallback_func)
        assert result["success"] is True
        assert result.get("used_fallback") is True

    def test_complete_failure(self):
        """æ¸¬è©¦å®Œå…¨å¤±æ•—çš„æƒ…æ³"""
        handler = RetryHandler(max_attempts=2, base_delay=0.1)

        def always_fail():
            raise EventStreamError({"Error": {"Message": "error"}}, "TestOp")

        result = handler.execute_with_retry(always_fail)
        assert result["success"] is False
        assert result["attempts"] == 2
        assert result["error"] is not None

    def test_non_retryable_error(self):
        """æ¸¬è©¦ä¸å¯é‡è©¦çš„éŒ¯èª¤"""
        handler = RetryHandler(max_attempts=3, base_delay=0.1)

        def non_retryable_func():
            raise ValueError("Invalid input")

        result = handler.execute_with_retry(non_retryable_func)
        assert result["success"] is False
        assert result["attempts"] == 3  # åªå˜—è©¦ä¸€æ¬¡å°±åœæ­¢

    def test_is_retryable_event_stream_error(self):
        """æ¸¬è©¦ EventStreamError å¯é‡è©¦"""
        handler = RetryHandler()
        error = EventStreamError({"Error": {"Message": "test"}}, "TestOp")
        assert handler._is_retryable(error) is True

    def test_is_retryable_throttling(self):
        """æ¸¬è©¦ Throttling éŒ¯èª¤å¯é‡è©¦"""
        handler = RetryHandler()
        error = ClientError(
            {"Error": {"Code": "ThrottlingException", "Message": "Rate exceeded"}}, "TestOp"
        )
        assert handler._is_retryable(error) is True

    def test_calculate_delay(self):
        """æ¸¬è©¦å»¶é²è¨ˆç®—"""
        handler = RetryHandler(base_delay=2.0)
        assert handler._calculate_delay(1) == 2.0
        assert handler._calculate_delay(2) == 4.0
        assert handler._calculate_delay(3) == 8.0
        assert handler._calculate_delay(10) == 10.0  # æœ€å¤§ 10 ç§’


class TestContextAnalyzer:
    """æ¸¬è©¦ Context åˆ†æå™¨"""

    def test_estimate_tokens(self):
        """æ¸¬è©¦ token ä¼°ç®—"""
        text = "æ¸¬è©¦" * 100  # 200 å­—å…ƒ
        tokens = estimate_tokens(text)
        assert tokens > 0
        assert tokens == 80  # 200 / 2.5 = 80

    def test_estimate_tokens_with_dict(self):
        """æ¸¬è©¦å­—å…¸çš„ token ä¼°ç®—"""
        data = {"key": "value", "nested": {"a": 1, "b": 2}}
        tokens = estimate_tokens(data)
        assert tokens > 0

    def test_estimate_tokens_with_list(self):
        """æ¸¬è©¦åˆ—è¡¨çš„ token ä¼°ç®—"""
        data = ["item1", "item2", "item3"]
        tokens = estimate_tokens(data)
        assert tokens > 0

    def test_analyze_context_size_basic(self):
        """æ¸¬è©¦åŸºæœ¬ context åˆ†æ"""
        analysis = analyze_context_size(messages="test message")
        assert analysis["total_tokens"] > 0
        assert analysis["warning_level"] == "normal"
        assert analysis["is_large"] is False

    def test_analyze_context_size_warning(self):
        """æ¸¬è©¦ warning ç´šåˆ¥"""
        large_text = "x" * 300000  # ~120K tokens (ç¢ºä¿è¶…é 100K)
        analysis = analyze_context_size(messages=large_text)
        assert analysis["warning_level"] == "warning"
        assert analysis["is_large"] is True

    def test_analyze_context_size_critical(self):
        """æ¸¬è©¦ critical ç´šåˆ¥"""
        huge_text = "x" * 400000  # ~160K tokens
        analysis = analyze_context_size(messages=huge_text)
        assert analysis["warning_level"] == "critical"
        assert analysis["is_large"] is True

    def test_analyze_with_images(self):
        """æ¸¬è©¦åŒ…å«åœ–ç‰‡çš„åˆ†æ"""
        images = [{"data": "base64..."}, {"data": "base64..."}]
        analysis = analyze_context_size(messages="test", images=images)
        assert analysis["images_count"] == 2
        assert analysis["images_tokens"] == 2000  # 2 * 1000

    def test_should_truncate_context(self):
        """æ¸¬è©¦æ˜¯å¦æ‡‰è©²æˆªæ–·"""
        # æ­£å¸¸å¤§å°
        normal_analysis = {"total_tokens": 50000, "is_large": False}
        assert should_truncate_context(normal_analysis) is False

        # éå¤§
        large_analysis = {"total_tokens": 160000, "is_large": True}
        assert should_truncate_context(large_analysis) is True

    def test_analyze_with_memory_and_tools(self):
        """æ¸¬è©¦åŒ…å« Memory å’Œå·¥å…·çµæœçš„åˆ†æ"""
        analysis = analyze_context_size(
            messages="test message",
            memory_context={"history": ["msg1", "msg2"]},
            tool_results={"result": "data"},
        )
        assert analysis["memory_tokens"] > 0
        assert analysis["tool_results_tokens"] > 0
        assert analysis["total_tokens"] > 0

    def test_get_truncation_suggestion(self):
        """æ¸¬è©¦æˆªæ–·å»ºè­°"""
        from utils.context_analyzer import get_truncation_suggestion

        # æ­£å¸¸å¤§å°
        normal = {"total_tokens": 50000, "memory_tokens": 10000, "tool_results_tokens": 5000}
        suggestion = get_truncation_suggestion(normal)
        assert suggestion["should_truncate"] is False

        # Memory éå¤§
        large_memory = {
            "total_tokens": 160000,
            "memory_tokens": 60000,
            "tool_results_tokens": 5000,
        }
        suggestion = get_truncation_suggestion(large_memory)
        assert suggestion["should_truncate"] is True
        assert "limit_memory" in suggestion["suggestions"]


class TestErrorHandlingIntegration:
    """æ¸¬è©¦éŒ¯èª¤è™•ç†æ•´åˆ"""

    def test_retry_with_error_formatting(self):
        """æ¸¬è©¦é‡è©¦å¤±æ•—å¾Œçš„éŒ¯èª¤æ ¼å¼åŒ–"""
        handler = RetryHandler(max_attempts=2, base_delay=0.1)

        def fail_func():
            raise EventStreamError({"Error": {"Message": "stream error"}}, "TestOp")

        result = handler.execute_with_retry(fail_func)
        assert result["success"] is False

        # æ ¼å¼åŒ–éŒ¯èª¤çµ¦ç”¨æˆ¶
        # æ³¨æ„ï¼šEventStreamError ç‰©ä»¶æœ¬èº«å¯èƒ½ä¸åŒ…å«é—œéµå­—ï¼Œéœ€è¦ç”¨éŒ¯èª¤è¨Šæ¯å­—ä¸²
        error_msg = "modelStreamErrorException in ConverseStream operation"
        friendly_msg = format_error_response(error_msg, {"retry_count": result["attempts"]})
        assert "AI æœå‹™" in friendly_msg
        assert "é‡è©¦" in friendly_msg

    def test_context_analysis_with_error_decision(self):
        """æ¸¬è©¦ context åˆ†æé©…å‹•éŒ¯èª¤æ±ºç­–"""
        # æ¨¡æ“¬å¤§ context
        large_text = "x" * 400000
        analysis = analyze_context_size(messages=large_text)

        # å¦‚æœ context éå¤§ï¼Œæ‡‰è©²å»ºè­°æ–°å°è©±
        if analysis["is_large"]:
            error = Exception(f"Context too large: {analysis['total_tokens']} tokens")
            assert should_suggest_new_conversation(error) is True  # Test comment
