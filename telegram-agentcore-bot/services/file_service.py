"""
æª”æ¡ˆè™•ç†æœå‹™
ä½¿ç”¨ AgentCore Code Interpreter è™•ç†æª”æ¡ˆ
"""
import os
import boto3
import base64
from typing import Dict, Any, Optional
from utils.logger import get_logger
from utils.audit import audit_log
from config.settings import settings

logger = get_logger(__name__)

# S3 å®¢æˆ¶ç«¯ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
_s3_client = None

def get_s3_client():
    """ç²å– S3 å®¢æˆ¶ç«¯å–®ä¾‹"""
    global _s3_client
    if _s3_client is None:
        _s3_client = boto3.client('s3')
    return _s3_client


class FileService:
    """æª”æ¡ˆè™•ç†æœå‹™é¡"""
    
    def __init__(self, region: str):
        """
        åˆå§‹åŒ–æª”æ¡ˆæœå‹™
        
        Args:
            region: AWS å€åŸŸ
        """
        self.region = region
        self.enabled = settings.FILE_ENABLED
        self.bucket = settings.FILE_STORAGE_BUCKET
        self.client = None
        
        if self.enabled:
            self._initialize_client()
        else:
            logger.info("ğŸ“ æª”æ¡ˆè™•ç†åŠŸèƒ½æœªå•Ÿç”¨")
    
    def _initialize_client(self):
        """åˆå§‹åŒ– Code Interpreter å®¢æˆ¶ç«¯"""
        try:
            from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter
            
            self.CodeInterpreter = CodeInterpreter
            logger.info("âœ… File Service åˆå§‹åŒ–æˆåŠŸ")
            
        except ImportError as e:
            logger.error(f"âŒ Code Interpreter åŒ¯å…¥å¤±æ•—: {str(e)}")
            self.enabled = False
    
    def is_available(self) -> bool:
        """æª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨"""
        return self.enabled and self.bucket != ''
    
    def read_from_s3(self, s3_url: str) -> Optional[bytes]:
        """
        å¾ S3 è®€å–æª”æ¡ˆ
        
        Args:
            s3_url: S3 URL (æ ¼å¼: s3://bucket/key)
        
        Returns:
            æª”æ¡ˆå…§å®¹ï¼ˆbytesï¼‰æˆ– None
        """
        try:
            # è§£æ S3 URL
            if not s3_url.startswith('s3://'):
                logger.error(f"Invalid S3 URL: {s3_url}")
                return None
            
            # ç§»é™¤ s3:// å‰ç¶´
            url_parts = s3_url[5:].split('/', 1)
            if len(url_parts) != 2:
                logger.error(f"Invalid S3 URL format: {s3_url}")
                return None
            
            bucket, key = url_parts
            
            # å¾ S3 è®€å–
            s3_client = get_s3_client()
            response = s3_client.get_object(Bucket=bucket, Key=key)
            file_content = response['Body'].read()
            
            logger.info(
                f"âœ… Read from S3: {len(file_content)} bytes",
                extra={
                    'event_type': 's3_read_success',
                    'bucket': bucket,
                    'key': key,
                    'size': len(file_content)
                }
            )
            
            return file_content
            
        except Exception as e:
            logger.error(
                f"âŒ Failed to read from S3: {str(e)}",
                extra={
                    'event_type': 's3_read_failure',
                    's3_url': s3_url
                },
                exc_info=True
            )
            return None
    
    def process_file(
        self, 
        s3_url: str,
        filename: str,
        task: str,
        user_id: str
    ) -> Dict[str, Any]:
        """
        è™•ç†æª”æ¡ˆ
        
        Args:
            s3_url: S3 URL
            filename: æª”æ¡ˆåç¨±
            task: è™•ç†ä»»å‹™æè¿°
            user_id: ç”¨æˆ¶ IDï¼ˆç”¨æ–¼å¯©è¨ˆï¼‰
        
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        if not self.is_available():
            return {
                "success": False,
                "error": "æª”æ¡ˆè™•ç†åŠŸèƒ½æœªå•Ÿç”¨æˆ–æœªé…ç½® S3 bucket"
            }
        
        session_id = None
        
        try:
            # å¯©è¨ˆï¼šè¨˜éŒ„æª”æ¡ˆè™•ç†é–‹å§‹
            audit_log(
                user_id=user_id,
                action="FILE_PROCESS_START",
                resource=filename,
                details={"task": task, "s3_url": s3_url}
            )
            
            # 1. å¾ S3 è®€å–æª”æ¡ˆ
            file_content = self.read_from_s3(s3_url)
            if not file_content:
                return {
                    "success": False,
                    "error": "ç„¡æ³•å¾ S3 è®€å–æª”æ¡ˆ"
                }
            
            logger.info(f"ğŸ“ é–‹å§‹è™•ç†æª”æ¡ˆ: {filename} ({len(file_content)} bytes)")
            
            # 2. å•Ÿå‹• Code Interpreter session
            client = self.CodeInterpreter(self.region)
            client.start()
            session_id = client.session_id
            logger.info(f"âœ… Code Interpreter session å·²å•Ÿå‹•: {session_id}")
            
            # 3. ä¸Šå‚³æª”æ¡ˆåˆ° session
            file_text = self._prepare_file_content(file_content, filename)
            
            write_response = client.invoke("writeFiles", {
                "content": [{
                    "path": filename,
                    "text": file_text
                }]
            })
            
            logger.info(f"âœ… æª”æ¡ˆå·²ä¸Šå‚³åˆ° session: {filename}")
            
            # 4. æ ¹æ“šä»»å‹™é¡å‹è™•ç†æª”æ¡ˆ
            result = self._execute_task(client, filename, task)
            
            # 5. åœæ­¢ session
            client.stop()
            session_id = None
            logger.info("âœ… Session å·²æ¸…ç†")
            
            # å¯©è¨ˆï¼šè¨˜éŒ„è™•ç†æˆåŠŸ
            audit_log(
                user_id=user_id,
                action="FILE_PROCESS_SUCCESS",
                resource=filename,
                details={"task": task, "result_length": len(str(result))}
            )
            
            return {
                "success": True,
                "result": result,
                "filename": filename
            }
            
        except Exception as e:
            logger.error(f"âŒ æª”æ¡ˆè™•ç†éŒ¯èª¤: {str(e)}", exc_info=True)
            
            # å¯©è¨ˆï¼šè¨˜éŒ„è™•ç†å¤±æ•—
            audit_log(
                user_id=user_id,
                action="FILE_PROCESS_FAILURE",
                resource=filename,
                details={"task": task, "error": str(e)}
            )
            
            return {
                "success": False,
                "error": f"è™•ç†å¤±æ•—: {str(e)}"
            }
            
        finally:
            # ç¢ºä¿ session è¢«æ¸…ç†
            if session_id and self.client:
                try:
                    self.client.stop()
                    logger.info(f"âœ… Session æ¸…ç†å®Œæˆ: {session_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Session æ¸…ç†å¤±æ•—: {str(e)}")
    
    def _prepare_file_content(self, content: bytes, filename: str) -> str:
        """
        æº–å‚™æª”æ¡ˆå…§å®¹ï¼ˆè½‰æ›ç‚ºæ–‡å­—ï¼‰
        
        Args:
            content: æª”æ¡ˆå…§å®¹ï¼ˆbytesï¼‰
            filename: æª”æ¡ˆåç¨±
        
        Returns:
            æ–‡å­—æ ¼å¼çš„æª”æ¡ˆå…§å®¹
        """
        # å˜—è©¦è§£ç¢¼ç‚º UTF-8
        try:
            return content.decode('utf-8')
        except UnicodeDecodeError:
            # å¦‚æœæ˜¯äºŒé€²ä½æª”æ¡ˆï¼Œä½¿ç”¨ base64 ç·¨ç¢¼
            logger.info(f"æª”æ¡ˆ {filename} ç‚ºäºŒé€²ä½æ ¼å¼ï¼Œä½¿ç”¨ base64 ç·¨ç¢¼")
            return base64.b64encode(content).decode('ascii')
    
    def _execute_task(self, client, filename: str, task: str) -> str:
        """
        åŸ·è¡Œè™•ç†ä»»å‹™
        
        Args:
            client: Code Interpreter å®¢æˆ¶ç«¯
            filename: æª”æ¡ˆåç¨±
            task: ä»»å‹™æè¿°
        
        Returns:
            è™•ç†çµæœæ–‡å­—
        """
        # æ ¹æ“šä»»å‹™é¡å‹ç”Ÿæˆä¸åŒçš„è™•ç†ç¨‹å¼ç¢¼
        if "æ‘˜è¦" in task or "summary" in task.lower():
            code = self._generate_summary_code(filename)
        elif "åˆ†æ" in task or "analyze" in task.lower():
            code = self._generate_analysis_code(filename)
        elif "çµ±è¨ˆ" in task or "statistics" in task.lower():
            code = self._generate_statistics_code(filename)
        else:
            # é è¨­ï¼šæ‘˜è¦
            code = self._generate_summary_code(filename)
        
        logger.info(f"åŸ·è¡Œä»»å‹™: {task}")
        
        # åŸ·è¡Œç¨‹å¼ç¢¼
        response = client.invoke("executeCode", {
            "code": code,
            "language": "python",
            "clearContext": False
        })
        
        # æå–çµæœ
        result = self._extract_result(response)
        return result
    
    def _generate_summary_code(self, filename: str) -> str:
        """ç”Ÿæˆæ‘˜è¦ç¨‹å¼ç¢¼"""
        return f"""
import os

# è®€å–æª”æ¡ˆ
with open('{filename}', 'r', encoding='utf-8') as f:
    content = f.read()
    lines = content.split('\\n')

# ç”Ÿæˆæ‘˜è¦
print("ğŸ“„ æª”æ¡ˆæ‘˜è¦")
print(f"æª”æ¡ˆåç¨±: {filename}")
print(f"ç¸½è¡Œæ•¸: {{len(lines)}}")
print(f"ç¸½å­—å…ƒæ•¸: {{len(content)}}")
print(f"æª”æ¡ˆå¤§å°: {{os.path.getsize('{filename}')}} bytes")
print()

# é¡¯ç¤ºå‰ 15 è¡Œå…§å®¹
print("ğŸ“ å‰ 15 è¡Œå…§å®¹:")
for i, line in enumerate(lines[:15], 1):
    # é™åˆ¶æ¯è¡Œæœ€å¤šé¡¯ç¤º 100 å­—å…ƒ
    display_line = line[:100] + "..." if len(line) > 100 else line
    print(f"{{i:2d}}. {{display_line}}")

if len(lines) > 15:
    print(f"\\n... (çœç•¥ {{len(lines) - 15}} è¡Œ)")
"""
    
    def _generate_analysis_code(self, filename: str) -> str:
        """ç”Ÿæˆåˆ†æç¨‹å¼ç¢¼ï¼ˆé‡å° CSV/JSONï¼‰"""
        return f"""
import os
import json

# åˆ¤æ–·æª”æ¡ˆé¡å‹
file_ext = os.path.splitext('{filename}')[1].lower()

print(f"ğŸ“Š æª”æ¡ˆåˆ†æ: {filename}")
print(f"æª”æ¡ˆé¡å‹: {{file_ext}}")
print()

if file_ext == '.csv':
    import csv
    with open('{filename}', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
        
        print(f"âœ… CSV æª”æ¡ˆåˆ†æ")
        print(f"ç¸½è¡Œæ•¸: {{len(rows)}}")
        
        if rows:
            print(f"\\næ¬„ä½æ¸…å–®:")
            for i, col in enumerate(rows[0].keys(), 1):
                print(f"  {{i}}. {{col}}")
            
            print(f"\\nå‰ 5 ç­†è³‡æ–™:")
            for i, row in enumerate(rows[:5], 1):
                print(f"\\nç¬¬ {{i}} ç­†:")
                for key, value in row.items():
                    display_value = str(value)[:50] + "..." if len(str(value)) > 50 else value
                    print(f"  - {{key}}: {{display_value}}")
            
            if len(rows) > 5:
                print(f"\\n... (çœç•¥ {{len(rows) - 5}} ç­†è³‡æ–™)")
            
elif file_ext == '.json':
    with open('{filename}', 'r', encoding='utf-8') as f:
        data = json.load(f)
        
        print(f"âœ… JSON æª”æ¡ˆåˆ†æ")
        print(f"è³‡æ–™é¡å‹: {{type(data).__name__}}")
        
        if isinstance(data, list):
            print(f"å…ƒç´ æ•¸é‡: {{len(data)}}")
            if data:
                print(f"\\nç¬¬ä¸€å€‹å…ƒç´ :")
                print(json.dumps(data[0], indent=2, ensure_ascii=False)[:500])
                
        elif isinstance(data, dict):
            print(f"\\nä¸»è¦éµå€¼:")
            for i, (key, value) in enumerate(list(data.items())[:10], 1):
                value_str = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                print(f"  {{i}}. {{key}}: {{value_str}}")
            
            if len(data) > 10:
                print(f"\\n... (çœç•¥ {{len(data) - 10}} å€‹éµ)")
                
else:
    # ä¸€èˆ¬æ–‡å­—æª”
    with open('{filename}', 'r', encoding='utf-8') as f:
        content = f.read()
        lines = content.split('\\n')
        
        print(f"âœ… æ–‡å­—æª”åˆ†æ")
        print(f"ç¸½è¡Œæ•¸: {{len(lines)}}")
        print(f"ç¸½å­—å…ƒæ•¸: {{len(content)}}")
        print(f"\\nå…§å®¹é è¦½ï¼ˆå‰ 500 å­—å…ƒï¼‰:")
        print(content[:500])
        if len(content) > 500:
            print(f"\\n... (å‰©é¤˜ {{len(content) - 500}} å­—å…ƒ)")
"""
    
    def _generate_statistics_code(self, filename: str) -> str:
        """ç”Ÿæˆçµ±è¨ˆåˆ†æç¨‹å¼ç¢¼"""
        return f"""
import os

file_ext = os.path.splitext('{filename}')[1].lower()

print(f"ğŸ“ˆ çµ±è¨ˆåˆ†æ: {filename}")
print()

if file_ext == '.csv':
    import csv
    with open('{filename}', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
        
        if not rows:
            print("æª”æ¡ˆç‚ºç©º")
        else:
            print(f"âœ… CSV çµ±è¨ˆè³‡è¨Š")
            print(f"ç¸½è¡Œæ•¸: {{len(rows)}}")
            print(f"æ¬„ä½æ•¸: {{len(rows[0].keys())}}")
            print(f"\\næ¬„ä½æ¸…å–®:")
            
            for col in rows[0].keys():
                # è¨ˆç®—éç©ºå€¼æ•¸é‡
                non_empty = sum(1 for row in rows if row.get(col, '').strip())
                print(f"  - {{col}}: {{non_empty}}/{{len(rows)}} ç­†æœ‰å€¼")
            
elif file_ext == '.json':
    import json
    with open('{filename}', 'r', encoding='utf-8') as f:
        data = json.load(f)
        
        print(f"âœ… JSON çµ±è¨ˆè³‡è¨Š")
        if isinstance(data, list):
            print(f"é™£åˆ—é•·åº¦: {{len(data)}}")
            if data and isinstance(data[0], dict):
                print(f"ç‰©ä»¶æ¬„ä½: {{', '.join(data[0].keys())}}")
        elif isinstance(data, dict):
            print(f"ç‰©ä»¶éµæ•¸é‡: {{len(data.keys())}}")
            print(f"ä¸»è¦éµå€¼: {{', '.join(list(data.keys())[:5])}}")
else:
    with open('{filename}', 'r', encoding='utf-8') as f:
        content = f.read()
        words = content.split()
        lines = content.split('\\n')
        
        print(f"âœ… æ–‡å­—çµ±è¨ˆ")
        print(f"ç¸½å­—æ•¸: {{len(words)}}")
        print(f"ç¸½è¡Œæ•¸: {{len(lines)}}")
        print(f"ç¸½å­—å…ƒæ•¸: {{len(content)}}")
        print(f"å¹³å‡æ¯è¡Œå­—æ•¸: {{len(words) / len(lines) if lines else 0:.1f}}")
"""
    
    def _extract_result(self, response: Any) -> str:
        """
        å¾éŸ¿æ‡‰ä¸­æå–çµæœ
        
        Args:
            response: Code Interpreter éŸ¿æ‡‰
        
        Returns:
            çµæœæ–‡å­—
        """
        result_text = ""
        
        try:
            # è™•ç† streaming response
            for event in response.get("stream", []):
                if "result" in event:
                    event_result = event["result"]
                    
                    # è™•ç†ä¸åŒçš„çµæœæ ¼å¼
                    if isinstance(event_result, dict):
                        # æå–æ–‡å­—è¼¸å‡º
                        if "output" in event_result:
                            result_text += str(event_result["output"])
                        elif "text" in event_result:
                            result_text += str(event_result["text"])
                        else:
                            result_text += str(event_result)
                    else:
                        result_text += str(event_result)
            
            # æ¸…ç†çµæœ
            result_text = result_text.strip()
            
            if not result_text:
                result_text = "è™•ç†å®Œæˆï¼Œä½†ç„¡è¼¸å‡ºå…§å®¹"
            
            return result_text
            
        except Exception as e:
            logger.error(f"çµæœæå–ç•°å¸¸: {str(e)}", exc_info=True)
            return f"çµæœæå–æ™‚ç™¼ç”Ÿå•é¡Œ: {str(e)}"
    
    def get_status(self) -> Dict[str, Any]:
        """
        å–å¾—æª”æ¡ˆæœå‹™ç‹€æ…‹
        
        Returns:
            ç‹€æ…‹è³‡è¨Šå­—å…¸
        """
        return {
            "enabled": self.enabled,
            "bucket": self.bucket if self.enabled else None,
            "region": self.region,
            "available": self.is_available()
        }


# å»ºç«‹å…¨åŸŸæª”æ¡ˆæœå‹™å¯¦ä¾‹
file_service = FileService(settings.AWS_REGION)
